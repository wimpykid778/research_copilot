### Mini-Survey on User-Centric AI Design and Interaction

The landscape of artificial intelligence (AI) is rapidly evolving, with a growing emphasis on user-centric design and interaction. This survey synthesizes insights from recent literature, highlighting key trends, research gaps, and future directions in the field.

#### User-Centric AI Design and Interaction

A recurring theme across the literature is the necessity for AI systems to be designed with the user in mind, particularly for non-technical users. This involves creating systems that not only provide explanations but also allow users to interact with and adapt AI systems to their needs [Paper 1], [Paper 2]. The transition from explainable AI (XAI) to interactive AI is seen as a crucial step in enhancing user engagement and collaboration [Paper 2]. Interactive AI systems are advocated for their potential to provide users with greater agency in AI development and evolution, moving beyond mere explainability and contestability [Paper 2].

#### Explainability and Trust in AI

Explainable AI is shown to significantly improve task performance and decision-making in human-AI collaboration, as demonstrated in empirical studies within manufacturing and medicine [Paper 4]. However, there remains a gap between technical and non-technical explanations, necessitating XAI methods that bridge this gap to foster trust and understanding among non-technical users [Paper 3]. Effective explanations should enable non-technical stakeholders to make informed decisions without requiring extensive educational efforts from AI experts [Paper 3].

#### Onboarding and Education

Effective onboarding processes are crucial, especially in fields like healthcare, where professionals may lack technical backgrounds. Providing benchmark information, practical benefits, and interaction trials can help contextualize AI performance and refine AI objectives [Paper 1]. Additionally, AI-based games are proposed as a novel method to study and improve users' mental models of AI, offering a more engaging and less intrusive way to understand user interactions with AI [Paper 6].

#### Human-AI Collaboration

AI has the potential to enhance human decision-making, but systems must allow users to validate AI predictions against their domain knowledge and overrule incorrect AI decisions [Paper 4]. This collaborative approach is essential for improving task performance and ensuring that AI systems are used effectively in practice.

#### Theoretical and Practical Value of AI

The distinction between "weak AI" and "strong AI" is discussed, with an emphasis on the practical value of "weak AI" in specific tasks, despite its limitations in achieving general intelligence [Paper 5]. While "weak AI" may not evolve into "strong AI," it still holds significant value in specific applications, such as image classification and speech recognition [Paper 5].

### Key Research Gaps

1. **Scalability and Generalizability:**
   Many studies are limited by small sample sizes or specific domains, which may not generalize to other fields or larger populations. Research is needed to test these findings across diverse settings and with larger, more representative samples [Paper 1], [Paper 4].

2. **Empirical Validation of Interactive AI:**
   While the literature highlights the need for more interactive AI systems, there is a lack of empirical studies demonstrating their practical application and effectiveness in real-world scenarios [Paper 2].

3. **Comprehensive Understanding of Mental Models:**
   Current methods for understanding users' mental models of AI are limited, particularly in capturing unconscious aspects. More research is needed to develop and validate methods, such as AI-based games, that can provide a deeper understanding of how users perceive and interact with AI [Paper 6].

4. **Bridging the Explanation Gap:**
   There is a significant gap in developing XAI methods that effectively communicate AI decisions to non-technical stakeholders. Research is needed to create and test explanation frameworks that are both technically accurate and easily understandable by non-experts [Paper 3].

5. **Integration of User Feedback in AI Development:**
   While user feedback is recognized as important, there is a lack of structured approaches for integrating this feedback into the iterative development of AI systems. Research should focus on methodologies that allow for continuous user input and adaptation of AI systems [Paper 2].

### Future Directions

Future research should focus on developing scalable and generalizable AI systems that are user-centric and interactive. Empirical validation of interactive AI systems in diverse real-world scenarios is crucial. Additionally, innovative methods for understanding and improving users' mental models of AI, such as AI-based games, should be further explored. Bridging the explanation gap and integrating user feedback into AI development will be key to fostering trust and enhancing the practical value of AI systems.

In conclusion, the evolution of AI towards more user-centric and interactive systems holds promise for improving human-AI collaboration and decision-making. Addressing the identified research gaps will be essential for realizing the full potential of AI in various domains.