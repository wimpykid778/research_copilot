**Mini-Survey on User-Centric Design and Interaction in AI Systems**

The development of AI systems has increasingly emphasized user-centric design, particularly in terms of explainability and interaction. This survey synthesizes insights from recent literature, highlighting key trends, research gaps, and future directions in the field.

**User-Centric Design and Interaction**

A recurring theme across the literature is the need for AI systems to be more user-centric, focusing on explainability and interaction. Explainable AI (XAI) is crucial for building trust, especially in high-stakes fields like healthcare and regulated industries [Paper 1], [Paper 3]. Effective explanations should be tailored to the audience's expertise, enabling users to understand and trust AI decisions [Paper 3]. This user-centric approach extends to onboarding processes, which are essential for integrating AI into professional workflows, particularly for non-technical users. Providing benchmark information, practical benefits, and interaction trials can help users contextualize AI performance and refine AI objectives [Paper 1].

**Explainability and Trust**

Explainability is a cornerstone of trust in AI systems. The literature emphasizes the importance of explanations that are comprehensible to non-technical stakeholders, who are often the primary users of AI systems [Paper 3]. Non-technical explanations should be designed to be readily understandable, enabling stakeholders to make informed decisions and actions [Paper 3]. In human-AI collaboration, explainable AI can significantly enhance task performance by allowing users to validate AI predictions against their domain knowledge, as demonstrated in experiments in manufacturing and medicine [Paper 4].

**Human-AI Collaboration and Mental Models**

Understanding users' mental models of AI is crucial for improving human-AI interaction. AI-based games and gameplay data offer innovative methods to study how users' mental models evolve, providing insights that traditional methods may miss [Paper 6]. This approach can advance the notion of human-centered XAI by offering a deeper understanding of user interactions with AI systems [Paper 6]. However, the literature on mental models of AI is limited, particularly in understanding how these models evolve during interactions [Paper 6].

**Research Gaps and Future Directions**

Despite the progress in user-centric AI design, several research gaps remain. Many studies are limited to specific domains or small sample sizes, which may not generalize to other fields or broader populations [Paper 1], [Paper 4]. More research is needed to validate findings across diverse applications and user groups. Additionally, while there is a call for more interactive AI systems, practical applications that allow for active user engagement and co-design are still limited [Paper 2]. Research should explore methods to empower users to adapt and influence AI systems actively.

Another significant gap is the lack of consensus on what constitutes an "explanation" in XAI, leading to potential misunderstandings between AI experts and non-technical stakeholders [Paper 3]. Further research is needed to standardize definitions and approaches to explainability. Moreover, the integration of theoretical and empirical approaches remains a challenge. Theoretical discussions on AI often lack empirical support, and bridging this gap could enhance the understanding and development of AI systems [Paper 5].

**Conclusion**

The literature underscores the importance of user-centric design and interaction in AI systems, with a strong emphasis on explainability and trust. While significant progress has been made, several research gaps remain, particularly in terms of generalizability, active user engagement, and the continuous evolution of mental models. Addressing these gaps will be crucial for advancing the field and ensuring that AI systems are both effective and trustworthy for diverse user groups. Future research should focus on developing standardized approaches to explainability, empowering users to actively engage with AI systems, and integrating theoretical and empirical insights to enhance AI development.